{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpZAAQH_AnX1"
      },
      "source": [
        "# Algoritmo de BackPropagation multiclase\n",
        "\n",
        "Este codigo se utilizará para entrenar la red neuronal de clasificacion de Nuestras Caras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3MCES9WMJEw"
      },
      "source": [
        "### Código en Python del Algoritmo de BackPropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsDfkqXaZR5q"
      },
      "source": [
        "La clase del dataset debe ser categorica\n",
        "Existe una clase en Python que resuelve el problema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0XkHjieK2xD"
      },
      "outputs": [],
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')\n",
        "!mkdir -p \"/content/.drive/My Drive/DMA\"\n",
        "!mkdir -p \"/content/buckets\"\n",
        "!ln -s \"/content/.drive/My Drive/DMA\" /content/buckets/b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtiWbym5uwI6"
      },
      "outputs": [],
      "source": [
        "# instalo  itables solo si no esta instalado\n",
        "!pip show itables >/dev/null || pip install itables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejqYzmGGLADY"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "from functools import reduce\n",
        "from itables import init_notebook_mode\n",
        "init_notebook_mode(all_interactive=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bYjXyHqLQFe"
      },
      "outputs": [],
      "source": [
        "# definicion de la clase de graficos\n",
        "\n",
        "class perceptron_plot:\n",
        "    \"\"\"plotting first hidden layer class\"\"\"\n",
        "    def __init__(self, X, Y, delay) -> None:\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.delay = delay\n",
        "        x1_min = np.min(X[:,0])\n",
        "        x2_min = np.min(X[:,1])\n",
        "        x1_max = np.max(X[:,0])\n",
        "        x2_max = np.max(X[:,1])\n",
        "        self.x1_min = x1_min - 0.1*(x1_max - x1_min)\n",
        "        self.x1_max = x1_max + 0.1*(x1_max - x1_min)\n",
        "        self.x2_min = x2_min - 0.1*(x2_max - x2_min)\n",
        "        self.x2_max = x2_max + 0.1*(x2_max - x2_min)\n",
        "        self.fig = plt.figure(figsize = (10,8))\n",
        "        self.ax = self.fig.subplots()\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max, auto=False)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max, auto=False)\n",
        "\n",
        "    def graficarVarias(self, W, x0, epoch, error) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + \"{0:.2E}\".format(error))\n",
        "        # ploteo puntos\n",
        "        num_classes = len(np.unique(self.Y))\n",
        "        # mycolors = plt.cm.get_cmap('tab10', num_classes)\n",
        "        scatter = self.ax.scatter(self.X[:,0], self.X[:,1], c=self.Y, s=20)\n",
        "        # self.ax.plot(self.X[:,0], self.X[:,1], 'o', c=vcolores,  markersize=2)\n",
        "\n",
        "\n",
        "        # dibujo las rectas\n",
        "        for i in range(len(x0)):\n",
        "            #vx2_min = -(W[0,i]*self.x1_min + x0[i])/W[1,i]\n",
        "            #vx2_max = -(W[0,i]*self.x1_max + x0[i])/W[1,i]\n",
        "            vx2_min = -(W[i,0]*self.x1_min + x0[i])/W[i,1]\n",
        "            vx2_max = -(W[i,0]*self.x1_max + x0[i])/W[i,1]\n",
        "\n",
        "            self.ax.plot([self.x1_min, self.x1_max],\n",
        "                         [vx2_min, vx2_max],\n",
        "                         linewidth = 2,\n",
        "                         color = 'red',\n",
        "                         alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DgbLgqe3gTp"
      },
      "outputs": [],
      "source": [
        "# definicion de las funciones de activacion\n",
        "#  y sus derivadas\n",
        "#  ahora agregando las versiones VECTORIZADAS\n",
        "\n",
        "def func_eval(fname, x):\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            y = x\n",
        "        case \"logsig\":\n",
        "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
        "        case \"tansig\":\n",
        "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
        "    return y\n",
        "\n",
        "# version vectorizada de func_eval\n",
        "func_eval_vec = np.vectorize(func_eval)\n",
        "\n",
        "\n",
        "def deriv_eval(fname, y):  #atencion que y es la entrada y=f( x )\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            d = 1.0\n",
        "        case \"logsig\":\n",
        "            d = y*(1.0-y)\n",
        "        case \"tansig\":\n",
        "            d = 1.0 - y*y\n",
        "    return d\n",
        "\n",
        "\n",
        "# version vectorizada de deriv_eval\n",
        "deriv_eval_vec = np.vectorize(deriv_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXinnKQIFnxU"
      },
      "source": [
        "### Clase  multiperceptron\n",
        "entrenar, predecir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gv7esD65dqu"
      },
      "outputs": [],
      "source": [
        "# definicion de la clase de multiperceptron\n",
        "\n",
        "class multiperceptron(object):\n",
        "    \"\"\"Multiperceptron class\"\"\"\n",
        "\n",
        "    # inicializacion de los pesos de todas las capas\n",
        "    def _red_init(self, semilla) -> None:\n",
        "        niveles = self.red['arq']['layers_qty']\n",
        "\n",
        "        np.random.seed(semilla)\n",
        "        for i in range(niveles):\n",
        "           nivel = dict()\n",
        "           nivel['id'] = i\n",
        "           nivel['last'] = (i==(niveles-1))\n",
        "           nivel['size'] = self.red[\"arq\"][\"layers_size\"][i]\n",
        "           nivel['func'] = self.red[\"arq\"][\"layers_func\"][i]\n",
        "\n",
        "           if( i==0 ):\n",
        "              entrada_size = self.red['arq']['input_size']\n",
        "           else:\n",
        "              entrada_size =  self.red['arq']['layers_size'][i-1]\n",
        "\n",
        "           salida_size =  nivel['size']\n",
        "\n",
        "           # los pesos, inicializados random\n",
        "           nivel['W'] = np.random.uniform(-0.5, 0.5, [salida_size, entrada_size])\n",
        "           nivel['w0'] = np.random.uniform(-0.5, 0.5, [salida_size, 1])\n",
        "\n",
        "           # los momentos, inicializados en CERO\n",
        "           nivel['W_m'] = np.zeros([salida_size, entrada_size])\n",
        "           nivel['w0_m'] = np.zeros([salida_size, 1])\n",
        "\n",
        "           self.red['layer'].append(nivel)\n",
        "\n",
        "    # constructor generico\n",
        "    def __init__(self) -> None:\n",
        "        self.data = dict()\n",
        "        self.red = dict()\n",
        "        self.carpeta = \"\"\n",
        "\n",
        "\n",
        "    # inicializacion full\n",
        "    def inicializar(self, df, campos, clase, hidden_layers_sizes, layers_func,\n",
        "                 semilla, carpeta) -> None:\n",
        "\n",
        "        # genero self.data\n",
        "        self.data['X'] = np.array( df.select(campos))\n",
        "        X_mean = self.data['X'].mean(axis=0)\n",
        "        X_sd = self.data['X'].std(axis=0)\n",
        "        self.data['X'] = (self.data['X'] - X_mean)/X_sd\n",
        "\n",
        "        #  Ylabel en  numpy\n",
        "        label =df.select(clase)\n",
        "        self.data['Ylabel'] = np.array(label).reshape(len(label))\n",
        "\n",
        "        # one-hot-encoding de Y\n",
        "        col_originales = df.columns\n",
        "        self.data['Y'] = np.array( df.to_dummies(clase).drop(col_originales, strict=False) )\n",
        "\n",
        "        col_dummies = sorted( list( set(df.to_dummies(clase).columns) -  set(col_originales)))\n",
        "        clases_originales = reduce(lambda acc, x: acc + [x[(len(clase)+1):]], col_dummies, [])\n",
        "\n",
        "        tamanos = hidden_layers_sizes\n",
        "        tamanos.append(self.data['Y'].shape[1])\n",
        "\n",
        "        arquitectura = {\n",
        "             'input_size' : self.data['X'].shape[1],\n",
        "             'input_mean' : X_mean,\n",
        "             'input_sd' :  X_sd,\n",
        "             'output_values' : clases_originales,\n",
        "             'layers_qty' : len(hidden_layers_sizes), # incluye la capa de salida, pero no la de entrada\n",
        "             'layers_size' : tamanos ,\n",
        "             'layers_func' : layers_func,\n",
        "        }\n",
        "\n",
        "        self.red['arq'] = arquitectura\n",
        "\n",
        "\n",
        "        # inicializo  work\n",
        "        self.red['work'] = dict()\n",
        "        self.red['work']['epoch'] = 0\n",
        "        self.red['work']['MSE'] = float('inf')\n",
        "        self.red['work']['train_error_rate'] = float('inf')\n",
        "\n",
        "        self.red['layer'] = list()\n",
        "        self._red_init(semilla)\n",
        "\n",
        "        # grabo el entorno\n",
        "        self.carpeta = carpeta\n",
        "        os.makedirs(self.carpeta, exist_ok=True)\n",
        "        with open(self.carpeta+\"/data.pkl\", 'wb') as f:\n",
        "            pickle.dump(self.data, f)\n",
        "\n",
        "        with open(self.carpeta+\"/red.pkl\", 'wb') as f:\n",
        "            pickle.dump(self.red, f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Algoritmo Backpropagation\n",
        "    def  entrenar(self, epoch_limit, MSE_umbral,\n",
        "               learning_rate, lr_momento, save_frequency,\n",
        "               retomar=True) -> None:\n",
        "\n",
        "        # si debo retomar\n",
        "        if( retomar):\n",
        "            with open(self.carpeta+\"/data.pkl\", 'rb') as f:\n",
        "              self.data = pickle.load(f)\n",
        "\n",
        "            with open(self.carpeta+\"/red.pkl\", 'rb') as f:\n",
        "              self.red = pickle.load(f)\n",
        "\n",
        "\n",
        "        # inicializaciones del bucle principal del backpropagation\n",
        "        epoch = self.red['work']['epoch']\n",
        "        MSE = self.red['work']['MSE']\n",
        "\n",
        "        # inicializacion del grafico\n",
        "        grafico = perceptron_plot(X=self.data['X'], Y=self.data['Ylabel'], delay=0.1)\n",
        "\n",
        "        # continuo mientras error cuadratico medio muy grande  y NO llegué al límite de epochs\n",
        "        Xfilas = self.data['X'].shape[0]\n",
        "        niveles = self.red[\"arq\"][\"layers_qty\"]\n",
        "\n",
        "        while ( MSE > MSE_umbral) and (epoch < epoch_limit) :\n",
        "          epoch += 1\n",
        "\n",
        "\n",
        "          # recorro siempre TODOS los registros de entrada\n",
        "          for fila in range(Xfilas):\n",
        "             # fila es el registro actual\n",
        "             x = self.data['X'][fila:fila+1,:]\n",
        "             clase = self.data['Y'][fila:fila+1,:]\n",
        "\n",
        "             # propagar el x hacia adelante, FORWARD\n",
        "             entrada = x.T  # la entrada a la red\n",
        "\n",
        "             # etapa forward\n",
        "             # recorro hacia adelante, nivel a nivel\n",
        "             vsalida =  [0] *(niveles) # salida de cada nivel de la red\n",
        "\n",
        "             for i in range(niveles):\n",
        "               estimulos = self.red['layer'][i]['W'] @ entrada + self.red['layer'][i]['w0']\n",
        "               vsalida[i] =  func_eval_vec(self.red['layer'][i]['func'], estimulos)\n",
        "               entrada = vsalida[i]  # para la proxima vuelta\n",
        "\n",
        "\n",
        "             # etapa backward\n",
        "             # calculo los errores en la capa hidden y la capa output\n",
        "             verror =  [0] *(niveles+1) # inicializo dummy\n",
        "             verror[niveles] = clase.T - vsalida[niveles-1]\n",
        "\n",
        "             i = niveles-1\n",
        "             verror[i] = verror[i+1] * deriv_eval_vec(self.red['layer'][i]['func'], vsalida[i])\n",
        "\n",
        "             for i in reversed(range(niveles-1)):\n",
        "               verror[i] = deriv_eval_vec(self.red['layer'][i]['func'], vsalida[i])*(self.red['layer'][i+1]['W'].T @ verror[i+1])\n",
        "\n",
        "             # ya tengo los errores que comete cada capa\n",
        "             # corregir matrices de pesos, voy hacia atras\n",
        "             # backpropagation\n",
        "             entrada = x.T\n",
        "             for i in range(niveles):\n",
        "               self.red['layer'][i]['W_m'] = learning_rate *(verror[i] @ entrada.T) + lr_momento *self.red['layer'][i]['W_m']\n",
        "               self.red['layer'][i]['w0_m'] = learning_rate * verror[i] + lr_momento * self.red['layer'][i]['w0_m']\n",
        "\n",
        "               self.red['layer'][i]['W']  =  self.red['layer'][i]['W'] + self.red['layer'][i]['W_m']\n",
        "               self.red['layer'][i]['w0'] =  self.red['layer'][i]['w0'] + self.red['layer'][i]['w0_m']\n",
        "               entrada = vsalida[i]  # para la proxima vuelta\n",
        "\n",
        "\n",
        "\n",
        "          # ya recalcule las matrices de pesos\n",
        "          # ahora avanzo la red, feed-forward\n",
        "          # para calcular el red(X) = Y\n",
        "          entrada = self.data['X'].T\n",
        "          for i in range(niveles):\n",
        "            estimulos = self.red['layer'][i]['W'] @ entrada + self.red['layer'][i]['w0']\n",
        "            salida =  func_eval_vec(self.red['layer'][i]['func'], estimulos)\n",
        "            entrada = salida  # para la proxima vuelta\n",
        "\n",
        "          # calculo el error cuadratico medio TODOS los X del dataset\n",
        "          MSE= np.mean( (self.data['Y'].T - salida)**2 )\n",
        "\n",
        "          # Grafico las rectas SOLAMENTE de la Primera Hidden Layer\n",
        "          # tengo que hacer w0.T[0]  para que pase el vector limpio\n",
        "          if( epoch % save_frequency == 0 ) or ( MSE <= MSE_umbral) or (epoch >= epoch_limit) :\n",
        "              # grafico\n",
        "              W = self.red['layer'][0]['W']\n",
        "              w0 = self.red['layer'][0]['w0']\n",
        "              grafico.graficarVarias(W, w0.T[0], epoch, MSE)\n",
        "\n",
        "              # almaceno en work\n",
        "              self.red['work']['epoch'] = epoch\n",
        "              self.red['work']['MSE'] = MSE\n",
        "              prediccion = np.argmax( salida.T, axis=1)\n",
        "              # prediccion\n",
        "              out = np.array(self.red[\"arq\"]['output_values'])\n",
        "              error_rate = np.mean( self.data['Ylabel'] != out[prediccion])\n",
        "              self.red[\"work\"]['train_error_rate'] = error_rate # error_rate != error cuadratico medio\n",
        "\n",
        "              # grabo a un archivo la red neuronal  entrenada por donde esté\n",
        "              #   solo la red, NO los datos\n",
        "              with open(carpeta+\"/red.pkl\", 'wb') as f:\n",
        "                 pickle.dump(self.red, f)\n",
        "\n",
        "        return (epoch, MSE, self.red['work']['train_error_rate'] )\n",
        "\n",
        "\n",
        "    # predigo a partir de modelo recien entrenado\n",
        "    def  predecir(self, df_new, campos, clase) -> None:\n",
        "        niveles = self.red['arq']['layers_qty']\n",
        "\n",
        "        # etapa forward\n",
        "        # recorro hacia adelante, nivel a nivel\n",
        "        X_new =  np.array( df_new.select(campos))\n",
        "\n",
        "\n",
        "        # estandarizo manualmente\n",
        "        #  con las medias y desvios que almacene durante el entrenamiento\n",
        "        X_new = (X_new - self.red['arq']['input_mean'])/self.red['arq']['input_sd']\n",
        "\n",
        "        # grafico los datos nuevos\n",
        "        Ylabel_new =df_new.select(clase)\n",
        "        Ylabel_new = np.array(Ylabel_new).reshape(len(Ylabel_new))\n",
        "        grafico = perceptron_plot(X=X_new, Y=Ylabel_new, delay=0.1)\n",
        "        W = self.red['layer'][0]['W']\n",
        "        w0 = self.red['layer'][0]['w0']\n",
        "        grafico.graficarVarias(W, w0.T[0], epoch, MSE)\n",
        "\n",
        "        # la entrada a la red,  el X que es TODO  x_new\n",
        "        entrada = X_new.T  # traspongo, necesito vectores columna\n",
        "\n",
        "        for i in range(niveles):\n",
        "          estimulos = self.red['layer'][i]['W'] @ entrada + self.red['layer'][i]['w0']\n",
        "          salida =  func_eval_vec(self.red['layer'][i]['func'], estimulos)\n",
        "          entrada = salida  # para la proxima vuelta\n",
        "\n",
        "        # me quedo con la neurona de la ultima capa que se activio con mayor intensidad\n",
        "        pred_idx = np.argmax( salida.T, axis=1)\n",
        "        pred_raw = np.max( salida.T, axis=1)\n",
        "\n",
        "        # calculo error_rate\n",
        "        out = np.array(self.red['arq']['output_values'])\n",
        "        error_rate = np.mean( np.array(df_new.select(\"y\") != out[pred_idx]))\n",
        "\n",
        "        return (out[pred_idx], pred_raw, error_rate)\n",
        "\n",
        "\n",
        "    # cargo un modelo ya entrenado, grabado en carpeta\n",
        "    def cargar_modelo(self, carpeta) -> None:\n",
        "        self.carpeta = carpeta\n",
        "\n",
        "        with open(self.carpeta+\"/red.pkl\", 'rb') as f:\n",
        "          self.red = pickle.load(f)\n",
        "\n",
        "        return (self.red['work']['epoch'],\n",
        "                self.red['work']['MSE'],\n",
        "                self.red['work']['train_error_rate'] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u3z27yD4aoF"
      },
      "source": [
        "## 1 Lectura del Dataset\n",
        "\n",
        "En este humilde y restringida version, la clase del dataset debe ser categorica, no es capaz de trabajar con clases continuas.\n",
        "La clase categorica puede ser  n-aria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpZ4JF8pLD11"
      },
      "outputs": [],
      "source": [
        "# Lectura del dataset con la moderna libreria Polars  (Pandas debe extinguirse!)\n",
        "\n",
        "df = pl.read_csv('https://storage.googleapis.com/open-courses/austral2025-af91/clusters02.txt', separator='\\t')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HM107y_4gzg"
      },
      "source": [
        "### 1.1 Particion  training/testing\n",
        "\n",
        "\n",
        "\n",
        "*   Es valido cambiar la *semilla_particion* para probar distintos <test, train> y asi estimar con mas precisión el error rate en testing  (Montecarlo Estimation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juIGBXiv64Lv"
      },
      "outputs": [],
      "source": [
        "# particion del dataset en training/testing\n",
        "\n",
        "semilla_particion = 102191\n",
        "pct_train = 0.75  # ratio de registros que va a training\n",
        "\n",
        "\n",
        "def train_test_split_df(df, seed=0, test_size=0.2):\n",
        "    return df.with_columns(\n",
        "        pl.int_range(pl.len(), dtype=pl.UInt32)\n",
        "        .shuffle(seed=seed)\n",
        "        .gt(pl.len() * test_size)\n",
        "        .alias(\"split\")\n",
        "    ).partition_by(\"split\", include_key=False)\n",
        "\n",
        "\n",
        "(df_train, df_test) = train_test_split_df(df,\n",
        "                                          seed=semilla_particion,\n",
        "                                          test_size=pct_train)\n",
        "\n",
        "# imprimo los tamaños\n",
        "print(\"Train:\", df_train.shape)\n",
        "print(\"Test:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaVDBHdeF_Ai"
      },
      "source": [
        "## 2  Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH__fEUO4mED"
      },
      "source": [
        "### 2.1  Inicializacion de la neural network\n",
        "\n",
        "\n",
        "\n",
        "*   Es valido cambiar la *semilla_red* para arrancar el entrenamiento con distintas rectas iniciales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FBNjEaQCXIH"
      },
      "outputs": [],
      "source": [
        "# defino la red multiperceptron\n",
        "carpeta = \"/content/buckets/b1/nn01/\"  # cambiar con cada corrida\n",
        "semilla_red = 200177  # define las rectas iniciales\n",
        "\n",
        "# una sola capa oculta de 2 neuronas  [2]\n",
        "# la capa oculta y la final tienen ambas logsig de activacion\n",
        "mp = multiperceptron()\n",
        "mp.inicializar(\n",
        "    df=df_train, campos=[\"x1\",\"x2\"], clase=\"y\",  # especificaion del dataset\n",
        "    hidden_layers_sizes=[4],  # no va la capa final, solo hidden layers\n",
        "    layers_func=['logsig','logsig'], # funciones de activacion de cada capa\n",
        "    semilla=semilla_red,\n",
        "    carpeta = carpeta\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt4VDBSb4rrn"
      },
      "source": [
        "### 2.2 Entrenamiento de la neural network = backpropagation\n",
        "\n",
        "Aqui se hace el trabajo pesado de entrenar la red neuronal\n",
        "\n",
        "Es necesario experimentar con\n",
        "\n",
        "\n",
        "*   learning_rate\n",
        "*   lr_momento\n",
        "*   epoch_limit  y MSE_umbral\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CvW7ZS8LoUt"
      },
      "outputs": [],
      "source": [
        "# entreno la neural netowork con BackPropagation\n",
        "\n",
        "# el entrenamiento\n",
        "(epoch, MSE, train_error_rate) = mp.entrenar(\n",
        "    epoch_limit=1500,\n",
        "    MSE_umbral=0.006,\n",
        "    learning_rate=0.2,\n",
        "    lr_momento=0.2,\n",
        "    save_frequency=100,\n",
        "    retomar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4X6DLWKA9Cv"
      },
      "source": [
        "#### Visualizacion de los resultados de la salida del entrenamiento de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY6RTcXO5vmj"
      },
      "outputs": [],
      "source": [
        "# las metricas basica de la red\n",
        "print(\"epoch :\", epoch)\n",
        "print(\"MSE :\", MSE)\n",
        "print(\"train_error_rate :\", train_error_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAlAN8M24i0c"
      },
      "outputs": [],
      "source": [
        "# la primera hidden layer\n",
        "print(\"W :\", mp.red[\"layer\"][0][\"W\"])\n",
        "print()\n",
        "print(\"w0 :\", mp.red[\"layer\"][0][\"w0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ZtSAAyRZJJ"
      },
      "source": [
        "### 2.3 Entrenamiento en caso de retomar\n",
        "\n",
        "\n",
        "\n",
        "*   Si se cortó el colab\n",
        "*   Si quiero extender la corrida a mas epochs\n",
        "*   Si quiero cambiar el learninh_rate\n",
        "*   Si quiero cambiar el MSE_umbral\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUthWw74RecV"
      },
      "outputs": [],
      "source": [
        "(epoch, MSE, train_error_rate) = mp.entrenar(\n",
        "    epoch_limit=1800, # aumento\n",
        "    MSE_umbral=0.001,\n",
        "    learning_rate=0.05,\n",
        "    lr_momento=0.05,\n",
        "    save_frequency=100,\n",
        "    retomar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmVzHk1uBSCO"
      },
      "source": [
        "Visualizacion de los resultados de salida de un post entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JhOPrW7cHlQ"
      },
      "outputs": [],
      "source": [
        "print(\"epoch :\", epoch)\n",
        "print(\"MSE :\", MSE)\n",
        "print(\"train_error_rate :\", train_error_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkHzn8Mr5zb9"
      },
      "outputs": [],
      "source": [
        "# la primera hidden layer\n",
        "print(\"W :\", mp.red[\"layer\"][0][\"W\"])\n",
        "print()\n",
        "print(\"w0 :\", mp.red[\"layer\"][0][\"w0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ApQFrX4wF5"
      },
      "source": [
        "## 3  Prediccion en los datos de Testing\n",
        "\n",
        "\n",
        "Se muestran los datos de testing, que son distintos a los de training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscBRJaDdqS7"
      },
      "source": [
        "### 3.1 Prediccion en caliente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmG4baz1kYtS"
      },
      "outputs": [],
      "source": [
        "# aplico la red entrenada al dataset de testing\n",
        "\n",
        "(y_hat,y_raw, test_error_rate) = mp.predecir(df_new=df_test, campos=['x1', 'x2'], clase='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ9Fm1dzBsNu"
      },
      "source": [
        "#### Visualizacion del error en testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTkTRyXt6CuO"
      },
      "outputs": [],
      "source": [
        "print(\"error_rate (train, test): \",  train_error_rate, test_error_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5NT12b4B1Vf"
      },
      "source": [
        "#### Visualizacion de la prediccion en testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnEcIAV7slNW"
      },
      "outputs": [],
      "source": [
        "tb_salida_test = pl.DataFrame( {\"clase\":df_test[\"y\"], \"pred\":y_hat, \"y_raw\":y_raw })\n",
        "tb_salida_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vjspZVPdwQG"
      },
      "source": [
        "## 4 Prediccion en datos NUEVOS\n",
        "\n",
        "\n",
        "*   La red fue entrenada en el pasado, y se grabó al drive\n",
        "*   Ya no esta disponible la sesion donde se entreno\n",
        "*   No quiero volver a entrenar de cero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2htu2gdK7Clx"
      },
      "outputs": [],
      "source": [
        "# cargo datos NUEVOS\n",
        "df_new = pl.read_csv('https://storage.googleapis.com/open-courses/austral2025-af91/nuevos02.txt', separator='\\t')\n",
        "df_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7sLsqi9dzWc"
      },
      "outputs": [],
      "source": [
        "# cargo modelo grabado y lo aplico a los datos nuevos\n",
        "\n",
        "carpeta = \"/content/buckets/b1/nn01/\"  # la carpeta del modelo entrenado\n",
        "\n",
        "mp_frio = multiperceptron()\n",
        "(epoch, MSE, train_error_rate) = mp_frio.cargar_modelo(carpeta)\n",
        "\n",
        "(y_hat, y_raw, new_error_rate) = mp_frio.predecir(df_new=df_new, campos=['x1', 'x2'], clase='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBEXEipeB-KW"
      },
      "source": [
        "#### Visualizacion del error modeloa aplicado a datos nuevos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Exvy_youeFLz"
      },
      "outputs": [],
      "source": [
        "print(\"error_rate (train, new): \",  train_error_rate, new_error_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizacion de la prediccion en datos nuevos"
      ],
      "metadata": {
        "id": "S6gJyIv1LGOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YONa1F9-eHQ6"
      },
      "outputs": [],
      "source": [
        "tb_salida_new = pl.DataFrame( {\"clase\":df_new[\"y\"], \"pred\":y_hat, \"y_raw\":y_raw })\n",
        "tb_salida_new"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}