{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron no  lineal, de Widrow\n",
        "\n"
      ],
      "metadata": {
        "id": "wpZAAQH_AnX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big Picture"
      ],
      "metadata": {
        "id": "ldkzf-kNOooG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src= 'https://storage.googleapis.com/open-courses/imagenes-5c33/DeepLearningTimeline.jpg' />"
      ],
      "metadata": {
        "id": "66I37uRFOu2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camino a Seguir\n",
        "\n",
        "\n",
        "*   Perceptron de Rosenblatt\n",
        "*   Perceptron de Widrow\n",
        "*   Multiperceptron, backpropagation\n"
      ],
      "metadata": {
        "id": "BGehd_mo6kjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo desde el punto de vista Matemático"
      ],
      "metadata": {
        "id": "5WLeolPFG6MX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Objetivo Primario"
      ],
      "metadata": {
        "id": "EjFvKhkJ83Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src= 'https://storage.googleapis.com/open-courses/imagenes-5c33/XOR.jpg' />\n",
        "\n",
        "<p> Los perceptrones (Rosenblatt, Widrow) separan linealmente a puntos del espacio </p>\n",
        "\n",
        "<p> Para separar puntos que NO son linealmente separables, necesito de varios perceptrones </p>\n",
        "\n",
        "<p> Construire una Deep Neural Network de varios hidden layers y aprendere a modificar los pesos de cada layer propagando hacia atras los errores </p>"
      ],
      "metadata": {
        "id": "YczJGmypG9sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo  BackPropagation\n",
        "\n",
        "\n",
        "\n",
        "*   Etapa forward,  avance normal de la red\n",
        "*   Etapa backward, propago los errores hacia atras\n",
        "\n"
      ],
      "metadata": {
        "id": "_00qTXojaykH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Etapa  Forward"
      ],
      "metadata": {
        "id": "gZ6gKdKizR3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/forward01.jpg' />"
      ],
      "metadata": {
        "id": "Vvar-hHBW1hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/forward02.jpg' />"
      ],
      "metadata": {
        "id": "oL-4CqJuze9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/forward03.jpg' />"
      ],
      "metadata": {
        "id": "GzGdRdszzrF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa  Backward"
      ],
      "metadata": {
        "id": "60kckL4AzvGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/back01.jpg' />"
      ],
      "metadata": {
        "id": "NNE45Lqez1JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/back02.jpg' />"
      ],
      "metadata": {
        "id": "X_LIuxRJz5uZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/back04.jpg' />"
      ],
      "metadata": {
        "id": "Jlj2WOvtz_gX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/back03.jpg' />"
      ],
      "metadata": {
        "id": "p5tF742Nz734"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resumen"
      ],
      "metadata": {
        "id": "gceQU0Iy0CTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/resumen01.jpg' />"
      ],
      "metadata": {
        "id": "eJ6d6HTe0E9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/resumen02.jpg' />"
      ],
      "metadata": {
        "id": "cd17wmiV0Jwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/resumen03.jpg' />"
      ],
      "metadata": {
        "id": "81JbQg_80MBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/resumen04.jpg' />"
      ],
      "metadata": {
        "id": "M9N8s7kE0PF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código en Python del Algoritmo de BackPropagation"
      ],
      "metadata": {
        "id": "f3MCES9WMJEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código en Python que grafica como van evolucionando las rectas que separan a los positivos de los negativos"
      ],
      "metadata": {
        "id": "GsDfkqXaZR5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')\n",
        "!mkdir -p \"/content/.drive/My Drive/DMA\"\n",
        "!mkdir -p \"/content/buckets\"\n",
        "!ln -s \"/content/.drive/My Drive/DMA\" /content/buckets/b1"
      ],
      "metadata": {
        "id": "_0XkHjieK2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ejqYzmGGLADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de las funciones de activacion\n",
        "#  y sus derivadas\n",
        "#  ahora agregando las versiones VECTORIZADAS\n",
        "\n",
        "def func_eval(fname, x):\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            y = x\n",
        "        case \"logsig\":\n",
        "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
        "        case \"tansig\":\n",
        "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
        "    return y\n",
        "\n",
        "# version vectorizada de func_eval\n",
        "func_eval_vec = np.vectorize(func_eval)\n",
        "\n",
        "\n",
        "def deriv_eval(fname, y):  #atencion que y es la entrada y=f( x )\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            d = 1.0\n",
        "        case \"logsig\":\n",
        "            d = y*(1.0-y)\n",
        "        case \"tansig\":\n",
        "            d = 1.0 - y*y\n",
        "    return d\n",
        "\n",
        "\n",
        "# version vectorizada de deriv_eval\n",
        "deriv_eval_vec = np.vectorize(deriv_eval)"
      ],
      "metadata": {
        "id": "EJaEOFujbreS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de la clase de graficos, NO hay x0 = 1\n",
        "\n",
        "class perceptron_plot:\n",
        "    def __init__(self, X, Y, delay) -> None:\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.delay = delay\n",
        "        x1_min = np.min(X[:,0])\n",
        "        x2_min = np.min(X[:,1])\n",
        "        x1_max = np.max(X[:,0])\n",
        "        x2_max = np.max(X[:,1])\n",
        "        self.x1_min = x1_min - 2.0*(x1_max - x1_min)\n",
        "        self.x1_max = x1_max + 2.0*(x1_max - x1_min)\n",
        "        self.x2_min = x2_min - 2.0*(x2_max - x2_min)\n",
        "        self.x2_max = x2_max + 2.0*(x2_max - x2_min)\n",
        "        self.fig = plt.figure(figsize = (10,8))\n",
        "        self.ax = self.fig.subplots()\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max, auto=False)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max, auto=False)\n",
        "\n",
        "    def graficar(self, W, x0, epoch, fila) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila) )\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,0], self.X[self.Y==1,1], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==0,0], self.X[self.Y==0,1], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,0], self.X[fila,1], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        #dibujo le recta\n",
        "        vx2_min = -(W[0]*self.x1_min + x0)/W[1]\n",
        "        vx2_max = -(W[0]*self.x1_max + x0)/W[1]\n",
        "\n",
        "        self.ax.plot([self.x1_min, self.x1_max],\n",
        "                     [vx2_min, vx2_max],\n",
        "                     linewidth = 2,\n",
        "                     color = 'red',\n",
        "                     alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n",
        "\n",
        "\n",
        "    def graficarVarias(self, W, x0, epoch, fila) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila))\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,0], self.X[self.Y==1,1], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==-1,0], self.X[self.Y==-1,1], 'o', color=\"blue\", markersize=10)\n",
        "        self.ax.plot(self.X[self.Y==0,0], self.X[self.Y==0,1], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,0], self.X[fila,1], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        # dibujo las rectas\n",
        "        for i in range(len(x0)):\n",
        "            #vx2_min = -(W[0,i]*self.x1_min + x0[i])/W[1,i]\n",
        "            #vx2_max = -(W[0,i]*self.x1_max + x0[i])/W[1,i]\n",
        "            vx2_min = -(W[i,0]*self.x1_min + x0[i])/W[i,1]\n",
        "            vx2_max = -(W[i,0]*self.x1_max + x0[i])/W[i,1]\n",
        "\n",
        "            self.ax.plot([self.x1_min, self.x1_max],\n",
        "                         [vx2_min, vx2_max],\n",
        "                         linewidth = 2,\n",
        "                         color = 'red',\n",
        "                         alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n"
      ],
      "metadata": {
        "id": "3bYjXyHqLQFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Los datos que debe modelar la  Deep Neural Network\n",
        "# El simple XOR,   de -1 a 1\n",
        "\n",
        "registros = [[-1, -1], [-1, 1], [1, -1],[1, 1]]\n",
        "clases = [-1, 1, 1, -1]\n",
        "\n",
        "# Paso las listas a numpy\n",
        "X = np.array(registros)\n",
        "Y = np.array(clases).reshape(len(clases),1) # vector columna\n",
        "\n",
        "# con estos puntos NO hace falta estandarizar"
      ],
      "metadata": {
        "id": "SpZ4JF8pLD11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# Tamano datos\n",
        "\n",
        "X_row = X.shape[0]\n",
        "X_col = X.shape[1]\n",
        "\n",
        "Y_col = 1"
      ],
      "metadata": {
        "id": "7HFhOlLvZl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# Input Layer - Capa de entrada\n",
        "\n",
        "input_size = X_col  # Tantas neuronas de entrada como campos de la tabla"
      ],
      "metadata": {
        "id": "X0mGwCkrd52b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# 1st  Hidden Layer\n",
        "\n",
        "hidden01_size = 2  # neuronas de la  Primera capa oculta\n",
        "hidden01_FUNC = 'logsig'  # uso la logistica  [0, 1]"
      ],
      "metadata": {
        "id": "iGdmbnFheQKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# 2nd  Hidden Layer\n",
        "\n",
        "# no va nada, NO hay en este caso segunda capa oculta"
      ],
      "metadata": {
        "id": "nB70p7syecPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# 3rd  Hidden Layer\n",
        "\n",
        "# no va nada, NO hay en este caso tercera capa oculta"
      ],
      "metadata": {
        "id": "Qonq6R7Oe6Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# Output Layer - Capa de salida\n",
        "\n",
        "output_size = Y_col  # Tantas neuronas de salida como campos de Y (uno solo)\n",
        "output_FUNC = 'tansig'  # uso la tangente hiperbolica [-1, 1]"
      ],
      "metadata": {
        "id": "_qux3-03em42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seteo de la semilla aleatoria\n",
        "np.random.seed(102191) # mi querida random seed para que las corridas sean reproducibles"
      ],
      "metadata": {
        "id": "Sr3jG9g7fPeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incializo las matrices de pesos azarosamente\n",
        "\n",
        "# W01 es la matriz de pesos que va del input a la Primera capa oculta\n",
        "W01 = np.random.uniform(-0.5, 0.5, [hidden01_size, input_size])\n",
        "X01 = np.random.uniform(-0.5, 0.5, [hidden01_size, 1] )\n",
        "\n",
        "# W02 es la matriz de pesos que vn de la primera capa oculta a la capa de salida\n",
        "W02 = np.random.uniform(-0.5, 0.5, [output_size, hidden01_size])\n",
        "X02 = np.random.uniform(-0.5, 0.5, [output_size, 1] )"
      ],
      "metadata": {
        "id": "pWseyXcQLklN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# controles del entrenamiento\n",
        "\n",
        "# Limite de lo que estoy dispuesto a trabajar\n",
        "epoch_limit = 5000    # para terminar si no converge\n",
        "\n",
        "# cuando la mejora del error sea inferior a este valor, me detendré\n",
        "error_delta_umbral = 1.0e-07\n",
        "\n",
        "# controla la velocidad de convergencia\n",
        "learning_rate = 0.2\n",
        "\n",
        "# controla cada cuanto se grafica un epoch\n",
        "demora_impresion = 0.1  # segundos"
      ],
      "metadata": {
        "id": "2CvW7ZS8LoUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializaciones del bucle\n",
        "\n",
        "epoch = 0\n",
        "error_epoch = float('inf')\n",
        "error_ant =  0.0"
      ],
      "metadata": {
        "id": "nIOgkeEiyGnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el bucle principal del algoritmo BackPropagation\n",
        "\n",
        "grafico = perceptron_plot(X=X, Y=Y.T[0], delay=demora_impresion)\n",
        "\n",
        "# continuo mientras en la iteración anterior modifique algo  y NO llegué al límite de epochs\n",
        "while ((math.fabs(error_epoch - error_ant) > error_delta_umbral) and (epoch < epoch_limit)):\n",
        "    epoch += 1\n",
        "    error_suma = 0.0\n",
        "    error_ant = error_epoch\n",
        "\n",
        "    # recorro siempre TODOS los registros de entrada\n",
        "    for fila in range(X_row):\n",
        "        # fila es el registro actual\n",
        "        x = X[fila:fila+1,:] # ej  array([[-1, -1]])\n",
        "        clase = Y[fila]\n",
        "\n",
        "        # etapa Forward\n",
        "        # propagar el input x hacia adelante\n",
        "        hidden01_estimulos = W01 @ x.T + X01\n",
        "        hidden01_salidas = func_eval_vec(hidden01_FUNC, hidden01_estimulos)\n",
        "\n",
        "        output_estimulos = W02 @ hidden01_salidas + X02\n",
        "        output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
        "\n",
        "        # etapa Backward\n",
        "        # calculo los errores en la capa hidden y la capa output\n",
        "        ErrorSalida = clase.T - output_salidas\n",
        "        # output_delta es un solo numero\n",
        "        output_delta = ErrorSalida * deriv_eval_vec(output_FUNC, output_salidas)\n",
        "        # hidden_delta es un vector columna\n",
        "        hidden_delta = deriv_eval_vec(hidden01_FUNC, hidden01_salidas)*(W02.T @ output_delta)\n",
        "\n",
        "        # ya tengo los errores que comete cada capa\n",
        "        # corregir matrices de pesos, voy hacia atras\n",
        "        # backpropagation\n",
        "        W01 = W01 + learning_rate * (hidden_delta @ x )\n",
        "        X01 = X01 + learning_rate * hidden_delta\n",
        "        W02 = W02 + learning_rate * (output_delta @ hidden01_salidas.T)\n",
        "        X02 = X02 + learning_rate * output_delta\n",
        "\n",
        "\n",
        "    # ya recalcule las matrices de pesos\n",
        "    # ahora avanzo la red, feed-forward\n",
        "    # para calcular el red(X) = Y\n",
        "    hidden01_estimulos = W01 @ X.T + X01\n",
        "    hidden01_salidas = func_eval_vec(hidden01_FUNC, hidden01_estimulos)\n",
        "\n",
        "    output_estimulos = W02 @ hidden01_salidas + X02\n",
        "    output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
        "\n",
        "\n",
        "    # calculo el error promedio general de TODOS los X\n",
        "    error_epoch= np.mean( (Y.T - output_salidas)**2 )\n",
        "\n",
        "    # Grafico las rectas de la Primer Hidden Layer\n",
        "    # tengo que hacer X01.T[0]  para que pase el vector\n",
        "    if( epoch % 10 == 0 ) : grafico.graficarVarias(W01, X01.T[0], epoch, -1)\n",
        "\n"
      ],
      "metadata": {
        "id": "G7Hd3D_FLs0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el error\n",
        "print(\"error_epoch= \", error_epoch)\n",
        "print(\"error_ant = \", error_ant)\n",
        "print(\"delta = \", math.fabs(error_epoch - error_ant))"
      ],
      "metadata": {
        "id": "f1eC6hRGyBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la cantidad de epochs necesarias hasta encontrar una solucion\n",
        "print(\"Para converger hicieron falta epochs=\",epoch)"
      ],
      "metadata": {
        "id": "JB4k9EeALy-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la matriz  W01 y X01, de la capa de entrada al primer Hidden Layer\n",
        "print( \"W01 = \", W01)\n",
        "print( \"X01 = \", X01)"
      ],
      "metadata": {
        "id": "6iqEFzBOexHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la matriz  W02 y X02, del primer Hidden Layer a la capa de salida\n",
        "print( \"W02 = \", W02)\n",
        "print( \"X02 = \", X02)"
      ],
      "metadata": {
        "id": "A15L2P95rtOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculo la salida de la red\n",
        "#  comprouebo que NO son valores 0 o 1\n",
        "#  lo que implica que deberé decidir mediante un umbral\n",
        "\n",
        "print( \"fila\\tclase\\testimulo\\ty=f(estimulo)\")\n",
        "for fila in range(X_row):\n",
        "    # fila es el registro actual\n",
        "    x = X[fila:fila+1,:]\n",
        "    clase = Y[fila]\n",
        "\n",
        "    # propagar el x hacia adelante\n",
        "    hidden01_estimulos = W01 @ x.T + X01\n",
        "    hidden01_salidas = func_eval_vec(hidden01_FUNC, hidden01_estimulos)\n",
        "\n",
        "    output_estimulos = W02 @ hidden01_salidas + X02\n",
        "    output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
        "\n",
        "\n",
        "    # funcion de activacion\n",
        "    print( fila, \"\\t\", clase, \"\\t\", output_estimulos, \"\\t\", output_salidas)"
      ],
      "metadata": {
        "id": "ZSbZgl_ZoxPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}