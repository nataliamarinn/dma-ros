{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmo de BackPropagation Region del Plano\n",
        "\n"
      ],
      "metadata": {
        "id": "wpZAAQH_AnX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código en Python del Algoritmo de BackPropagation"
      ],
      "metadata": {
        "id": "f3MCES9WMJEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código en Python que grafica como van evolucionando las rectas que separan a los positivos de los negativos"
      ],
      "metadata": {
        "id": "GsDfkqXaZR5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')\n",
        "!mkdir -p \"/content/.drive/My Drive/DMA\"\n",
        "!mkdir -p \"/content/buckets\"\n",
        "!ln -s \"/content/.drive/My Drive/DMA\" /content/buckets/b1"
      ],
      "metadata": {
        "id": "_0XkHjieK2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ejqYzmGGLADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de las funciones de activacion\n",
        "#  y sus derivadas\n",
        "#  ahora agregando las versiones VECTORIZADAS\n",
        "\n",
        "def func_eval(fname, x):\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            y = x\n",
        "        case \"logsig\":\n",
        "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
        "        case \"tansig\":\n",
        "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
        "    return y\n",
        "\n",
        "# version vectorizada de func_eval\n",
        "func_eval_vec = np.vectorize(func_eval)\n",
        "\n",
        "\n",
        "def deriv_eval(fname, y):  #atencion que y es la entrada y=f( x )\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            d = 1.0\n",
        "        case \"logsig\":\n",
        "            d = y*(1.0-y)\n",
        "        case \"tansig\":\n",
        "            d = 1.0 - y*y\n",
        "    return d\n",
        "\n",
        "\n",
        "# version vectorizada de deriv_eval\n",
        "deriv_eval_vec = np.vectorize(deriv_eval)"
      ],
      "metadata": {
        "id": "EJaEOFujbreS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de la clase de graficos, NO hay x0 = 1\n",
        "\n",
        "class perceptron_plot:\n",
        "    def __init__(self, X, Y, delay) -> None:\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.delay = delay\n",
        "        x1_min = np.min(X[:,0])\n",
        "        x2_min = np.min(X[:,1])\n",
        "        x1_max = np.max(X[:,0])\n",
        "        x2_max = np.max(X[:,1])\n",
        "        self.x1_min = x1_min - 0.5*(x1_max - x1_min)\n",
        "        self.x1_max = x1_max + 0.5*(x1_max - x1_min)\n",
        "        self.x2_min = x2_min - 0.5*(x2_max - x2_min)\n",
        "        self.x2_max = x2_max + 0.5*(x2_max - x2_min)\n",
        "        self.fig = plt.figure(figsize = (10,8))\n",
        "        self.ax = self.fig.subplots()\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max, auto=False)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max, auto=False)\n",
        "\n",
        "    def graficar(self, W, x0, epoch, fila) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila) )\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,0], self.X[self.Y==1,1], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==0,0], self.X[self.Y==0,1], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,0], self.X[fila,1], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        #dibujo le recta\n",
        "        vx2_min = -(W[0]*self.x1_min + x0)/W[1]\n",
        "        vx2_max = -(W[0]*self.x1_max + x0)/W[1]\n",
        "\n",
        "        self.ax.plot([self.x1_min, self.x1_max],\n",
        "                     [vx2_min, vx2_max],\n",
        "                     linewidth = 2,\n",
        "                     color = 'red',\n",
        "                     alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n",
        "\n",
        "\n",
        "    def graficarVarias(self, W, x0, epoch, fila) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila))\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,0], self.X[self.Y==1,1], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==-1,0], self.X[self.Y==-1,1], 'o', color=\"blue\", markersize=10)\n",
        "        self.ax.plot(self.X[self.Y==0,0], self.X[self.Y==0,1], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,0], self.X[fila,1], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        # dibujo las rectas\n",
        "        for i in range(len(x0)):\n",
        "            #vx2_min = -(W[0,i]*self.x1_min + x0[i])/W[1,i]\n",
        "            #vx2_max = -(W[0,i]*self.x1_max + x0[i])/W[1,i]\n",
        "            vx2_min = -(W[i,0]*self.x1_min + x0[i])/W[i,1]\n",
        "            vx2_max = -(W[i,0]*self.x1_max + x0[i])/W[i,1]\n",
        "\n",
        "            self.ax.plot([self.x1_min, self.x1_max],\n",
        "                         [vx2_min, vx2_max],\n",
        "                         linewidth = 2,\n",
        "                         color = 'red',\n",
        "                         alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n"
      ],
      "metadata": {
        "id": "3bYjXyHqLQFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Los datos que debe modelar la  Deep Neural Network\n",
        "# Leo de la web el dataset  de  \"cero\"  o el de  \"ocho\"\n",
        "\n",
        "import polars as pl\n",
        "\n",
        "df = pl.read_csv('https://storage.googleapis.com/open-courses/austral2025-af91/cero.txt', separator='\\t')\n",
        "\n",
        "registros = df.select([\"x1\",\"x2\"])\n",
        "clases =df.select(\"y\")\n",
        "\n",
        "# Paso las listas a numpy\n",
        "X = np.array(registros)\n",
        "Y = np.array(clases).reshape(len(clases),1) # vector columna\n",
        "\n",
        "# con estos puntos NO hace falta estandarizar"
      ],
      "metadata": {
        "id": "SpZ4JF8pLD11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de la red\n",
        "# Tamano datos\n",
        "\n",
        "X_row = X.shape[0]\n",
        "X_col = X.shape[1]\n",
        "\n",
        "Y_col = Y.shape[1]"
      ],
      "metadata": {
        "id": "7HFhOlLvZl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino manualmente la arquitectura de la red\n",
        "#  input es X_col e  Y_col\n",
        "\n",
        "# DOS hidden layers\n",
        "# el primer huddeb layer tiene 8 perceptrones\n",
        "\n",
        "arquitectura = {\n",
        "   \"input_size\" : X_col,\n",
        "   \"layers_qty\" : 3, # incluye la capa de salida, pero no la de entrada\n",
        "   \"layers_size\" : [8, 2, Y_col],\n",
        "   \"layers_func\" : ['logsig','logsig','logsig'],\n",
        "}\n"
      ],
      "metadata": {
        "id": "D80SSfszbrNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seteo de la semilla aleatoria\n",
        "np.random.seed(102191) # mi querida random seed para que las corridas sean reproducibles"
      ],
      "metadata": {
        "id": "1y3PJdmUfYiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializo la red con pesos al azar\n",
        "#   a partir de la arquitectura\n",
        "\n",
        "red = {\n",
        "    'arq' : arquitectura,\n",
        "    'layer' : list(),\n",
        "}\n",
        "\n",
        "niveles = red[\"arq\"][\"layers_qty\"]\n",
        "\n",
        "for i in range(niveles):\n",
        "  nivel = dict()\n",
        "  nivel[\"id\"] = i\n",
        "  nivel[\"last\"] = (i==(niveles-1))\n",
        "  nivel[\"size\"] = red[\"arq\"][\"layers_size\"][i]\n",
        "  nivel[\"func\"] = red[\"arq\"][\"layers_func\"][i]\n",
        "\n",
        "  if( i==0 ):\n",
        "    entrada_size = red[\"arq\"][\"input_size\"]\n",
        "  else:\n",
        "    entrada_size =  red[\"arq\"][\"layers_size\"][i-1]\n",
        "\n",
        "  salida_size =  nivel[\"size\"]\n",
        "  nivel[\"W\"] = np.random.uniform(-0.5, 0.5, [salida_size, entrada_size])\n",
        "  nivel[\"w0\"] = np.random.uniform(-0.5, 0.5, [salida_size, 1])\n",
        "\n",
        "  red[\"layer\"].append(nivel)\n",
        "\n",
        "\n",
        "print( red )"
      ],
      "metadata": {
        "id": "X0mGwCkrd52b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# controles del entrenamiento\n",
        "\n",
        "# Limite de lo que estoy dispuesto a trabajar\n",
        "epoch_limit = 10000    # para terminar si no converge\n",
        "\n",
        "# cuando la mejora del error sea inferior a este valor, me detendré\n",
        "error_delta_umbral = 1.0e-06\n",
        "\n",
        "# controla la velocidad de convergencia\n",
        "learning_rate = 0.2\n",
        "\n",
        "# controla cada cuanto se grafica un epoch\n",
        "demora_impresion = 0.1  # segundos"
      ],
      "metadata": {
        "id": "2CvW7ZS8LoUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializaciones del bucle principal del backpropagation\n",
        "\n",
        "epoch = 0\n",
        "error_epoch = float('inf')\n",
        "error_ant =  0.0"
      ],
      "metadata": {
        "id": "nIOgkeEiyGnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el bucle principal del algoritmo BackPropagation\n",
        "\n",
        "grafico = perceptron_plot(X=X, Y=Y.T[0], delay=demora_impresion)\n",
        "\n",
        "# continuo mientras en la iteración anterior modifique algo  y NO llegué al límite de epochs\n",
        "while (((math.fabs(error_epoch - error_ant) > error_delta_umbral) or( error_epoch>0.01) ) and (epoch < epoch_limit) ):\n",
        "    epoch += 1\n",
        "    error_suma = 0.0\n",
        "    error_ant = error_epoch\n",
        "\n",
        "    # recorro siempre TODOS los registros de entrada\n",
        "    for fila in range(X_row):\n",
        "        # fila es el registro actual\n",
        "        x = X[fila:fila+1,:] # ej  array([[-1, -1]])\n",
        "        clase = Y[fila]\n",
        "\n",
        "        # propagar el x hacia adelante, FORWARD\n",
        "        entrada = x.T  # la entrada a la red\n",
        "        niveles = red[\"arq\"][\"layers_qty\"]\n",
        "\n",
        "        # etapa forward\n",
        "        # recorro hacia adelante, nivel a nivel\n",
        "        vsalida =  [0] *(niveles) # salida de cada nivel de la red\n",
        "\n",
        "        for i in range(niveles):\n",
        "          estimulos = red[\"layer\"][i][\"W\"] @ entrada + red[\"layer\"][i][\"w0\"]\n",
        "          vsalida[i] =  func_eval_vec(red[\"layer\"][i][\"func\"], estimulos)\n",
        "          entrada = vsalida[i]  # para la proxima vuelta\n",
        "\n",
        "\n",
        "        # etapa backward\n",
        "        # calculo los errores en la capa hidden y la capa output\n",
        "        verror =  [0] *(niveles+1) # inicializo dummy\n",
        "        verror[niveles] = clase.T - vsalida[niveles-1]\n",
        "\n",
        "        i = niveles-1\n",
        "        verror[i] = verror[i+1] * deriv_eval_vec(red[\"layer\"][i][\"func\"], vsalida[i])\n",
        "\n",
        "        for i in reversed(range(niveles-1)):\n",
        "           verror[i] = deriv_eval_vec(red[\"layer\"][i][\"func\"], vsalida[i])*(red[\"layer\"][i+1][\"W\"].T @ verror[i+1])\n",
        "\n",
        "        # ya tengo los errores que comete cada capa\n",
        "        # corregir matrices de pesos, voy hacia atras\n",
        "        # backpropagation\n",
        "        entrada = x.T\n",
        "        for i in range(niveles):\n",
        "          red[\"layer\"][i][\"W\"]  =  red[\"layer\"][i][\"W\"] + learning_rate *(verror[i] @ entrada.T)\n",
        "          red[\"layer\"][i][\"w0\"] =  red[\"layer\"][i][\"w0\"] + learning_rate * verror[i]\n",
        "          entrada = vsalida[i]  # para la proxima vuelta\n",
        "\n",
        "\n",
        "\n",
        "    # ya recalcule las matrices de pesos\n",
        "    # ahora avanzo la red, feed-forward\n",
        "    # para calcular el red(X) = Y\n",
        "    entrada = X.T\n",
        "    for i in range(niveles):\n",
        "        estimulos = red[\"layer\"][i][\"W\"] @ entrada + red[\"layer\"][i][\"w0\"]\n",
        "        salida =  func_eval_vec(red[\"layer\"][i][\"func\"], estimulos)\n",
        "        entrada = salida  # para la proxima vuelta\n",
        "\n",
        "    output_salidas = salida  # salida tiene la salida del ultimo layer\n",
        "\n",
        "    # calculo el error promedio general de TODOS los X\n",
        "    error_epoch= np.mean( (Y.T - output_salidas)**2 )\n",
        "\n",
        "    # Grafico las rectas de la Primer Hidden Layer\n",
        "    # tengo que hacer w0.T[0]  para que pase el vector limpio\n",
        "    W = red[\"layer\"][0][\"W\"]\n",
        "    w0 = red[\"layer\"][0][\"w0\"]\n",
        "    if( epoch % 100 == 0 ) : grafico.graficarVarias(W, w0.T[0], epoch, -1)\n"
      ],
      "metadata": {
        "id": "G7Hd3D_FLs0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el error\n",
        "print(\"error_epoch= \", error_epoch)\n",
        "print(\"error_ant = \", error_ant)\n",
        "print(\"delta = \", math.fabs(error_epoch - error_ant))"
      ],
      "metadata": {
        "id": "f1eC6hRGyBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la cantidad de epochs necesarias hasta encontrar una solucion\n",
        "print(\"Para converger hicieron falta epochs=\",epoch)"
      ],
      "metadata": {
        "id": "JB4k9EeALy-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimo los niveles de la red\n",
        "for i in range(red[\"arq\"][\"layers_qty\"]):\n",
        "  print( red[\"layer\"][i])"
      ],
      "metadata": {
        "id": "6iqEFzBOexHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculo la salida de la red\n",
        "#  comprouebo que NO son valores 0 o 1\n",
        "#  lo que implica que deberé decidir mediante un umbral\n",
        "\n",
        "niveles = red[\"arq\"][\"layers_qty\"]\n",
        "\n",
        "print( \"fila\\tclase\\testimulo\\ty=f(estimulo)\")\n",
        "for fila in range(X_row):\n",
        "    # fila es el registro actual\n",
        "    x = X[fila:fila+1,:]\n",
        "    clase = Y[fila]\n",
        "    entrada = x.T  # la entrada a la red\n",
        "\n",
        "    # etapa forward\n",
        "    # recorro hacia adelante, nivel a nivel\n",
        "    for i in range(niveles):\n",
        "       estimulos = red[\"layer\"][i][\"W\"] @ entrada + red[\"layer\"][i][\"w0\"]\n",
        "       salida =  func_eval_vec(red[\"layer\"][i][\"func\"], estimulos)\n",
        "       entrada = salida  # para la proxima vuelta\n",
        "\n",
        "    # funcion de activacion\n",
        "    print( fila, \"\\t\", clase, \"\\t\", estimulos, \"\\t\", salida)"
      ],
      "metadata": {
        "id": "ZSbZgl_ZoxPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Kx0cuBhYkvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}